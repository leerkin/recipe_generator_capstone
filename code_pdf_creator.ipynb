{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T21:35:37.755558Z",
     "start_time": "2024-06-18T21:35:37.740164Z"
    }
   },
   "outputs": [],
   "source": [
    "# try to combine all the datasets to create a pdf with ingredients, aromatic\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import ast\n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "import requests\n",
    "import time\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "403125de44df77a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:51:26.075596Z",
     "start_time": "2024-06-18T19:51:24.634543Z"
    }
   },
   "outputs": [],
   "source": [
    "ingredients_df = pd.read_csv('data/recipes.csv')\n",
    "ingredients_df = pd.DataFrame(ingredients_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "888c2ea8d1001e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:47:36.198506Z",
     "start_time": "2024-06-18T20:47:36.181909Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "comp_path = 'data/flavor_network_data/ingr_comp/comp_info.tsv'\n",
    "comp_tsv = pd.read_csv(comp_path, delimiter='\\t')\n",
    "\n",
    "comp_df = pd.DataFrame(data = comp_tsv)\n",
    "comp_columns = ['compound_id', 'compound_name', 'CAS_number']\n",
    "comp_df.columns = comp_columns\n",
    "\n",
    "ingr_path = 'data/flavor_network_data/ingr_comp/ingr_info.tsv'\n",
    "ingr_tsv = pd.read_csv(ingr_path, delimiter='\\t')\n",
    "\n",
    "ingr_df = pd.DataFrame(data = ingr_tsv)\n",
    "ingr_columns = ['ingredient_id', 'ingredient_name', 'ingredient_category']\n",
    "ingr_df.columns = ingr_columns\n",
    "\n",
    "ingr_comp_pathh = 'data/flavor_network_data/ingr_comp/ingr_comp.tsv'\n",
    "ingr_comp_tsv = pd.read_csv(ingr_comp_pathh, delimiter='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dca224c6f35d388f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:51:29.451699Z",
     "start_time": "2024-06-18T19:51:29.448618Z"
    }
   },
   "outputs": [],
   "source": [
    "ingr_comp_df = pd.DataFrame(data = ingr_comp_tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f6081a5a925d5299",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:51:30.133044Z",
     "start_time": "2024-06-18T19:51:30.129890Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['# ingredient id', 'compound id'], dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingr_comp_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ef6255bd2c1a752",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:51:30.734092Z",
     "start_time": "2024-06-18T19:51:30.731574Z"
    }
   },
   "outputs": [],
   "source": [
    "ingr_comp_df.rename(columns={\n",
    "    '# ingredient id': 'ingredient_id',\n",
    "    'compound id': 'compound_id'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2a0ad90f47033c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:51:32.080806Z",
     "start_time": "2024-06-18T19:51:32.072392Z"
    }
   },
   "outputs": [],
   "source": [
    "flav_edges_path = 'data/flavor_network_data/flavor_network_backbone/flavor_network_backbone_edges.tsv'\n",
    "flav_edges_tsv = pd.read_csv(flav_edges_path, delimiter='\\t')\n",
    "\n",
    "flav_edges_df = pd.DataFrame(data = flav_edges_tsv)\n",
    "flav_edges_columns = ['ingredient_1', 'ingredient_2', 'number_of_shared_compounds']\n",
    "flav_edges_df.columns = flav_edges_columns\n",
    "\n",
    "flav_nodes_path = 'data/flavor_network_data/flavor_network_backbone/flavor_network_backbone_nodes.tsv'\n",
    "flav_nodes_tsv = pd.read_csv(flav_nodes_path, delimiter='\\t')\n",
    "\n",
    "flav_nodes_df = pd.DataFrame(data = flav_nodes_tsv)\n",
    "flav_nodes_columns = ['ingredient_name', 'x_coordinate', 'y_coordinate', 'prevalence', 'r', 'g', 'b']\n",
    "flav_nodes_df.columns = flav_nodes_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ec459e642b8d2444",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:51:32.907366Z",
     "start_time": "2024-06-18T19:51:32.905353Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to replace spaces with underscores\n",
    "def replace_spaces(value):\n",
    "    if isinstance(value, str):\n",
    "        return value.replace(' ', '_')\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ca0ec53f3770d467",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:51:33.522310Z",
     "start_time": "2024-06-18T19:51:33.516734Z"
    }
   },
   "outputs": [],
   "source": [
    "ingr_df['ingredient_name'] = ingr_df['ingredient_name'].apply(replace_spaces)\n",
    "ingr_df['ingredient_category'] = ingr_df['ingredient_category'].apply(replace_spaces)\n",
    "flav_edges_df['ingredient_1'] = flav_edges_df['ingredient_1'].apply(replace_spaces)\n",
    "flav_edges_df['ingredient_2'] = flav_edges_df['ingredient_2'].apply(replace_spaces)\n",
    "flav_nodes_df['ingredient_name'] = flav_nodes_df['ingredient_name'].apply(replace_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c52cc8603e7d3f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:51:34.423854Z",
     "start_time": "2024-06-18T19:51:34.412419Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "data = {\n",
    "    'Canada': 'NorthAmerican',\n",
    "    'Turkey': 'MiddleEastern',\n",
    "    'east_asian': 'EastAsian',\n",
    "    'Caribbean': 'LatinAmerican',\n",
    "    'Bangladesh': 'SouthAsian',\n",
    "    'chinese': 'EastAsian',\n",
    "    'mexico': 'LatinAmerican',\n",
    "    'Lebanon': 'MiddleEastern',\n",
    "    'japanese': 'EastAsian',\n",
    "    'North-African': 'African',\n",
    "    'MiddleEastern': 'MiddleEastern',\n",
    "    'Indian': 'SouthAsian',\n",
    "    'asian': 'EastAsian',\n",
    "    'Italy': 'SouthernEuropean',\n",
    "    'EasternEuropean_Russian': 'EasternEuropean',\n",
    "    'Israel': 'MiddleEastern',\n",
    "    'Korea': 'EastAsian',\n",
    "    'Iran': 'MiddleEastern',\n",
    "    'Eastern-Europe': 'EasternEuropean',\n",
    "    'Jewish': 'MiddleEastern',\n",
    "    'South-African': 'African',\n",
    "    'Vietnamese': 'SoutheastAsian',\n",
    "    'UK-and-Ireland': 'WesternEuropean',\n",
    "    'French': 'WesternEuropean',\n",
    "    'Mediterranean': 'SouthernEuropean',\n",
    "    'Central_SouthAmerican': 'LatinAmerican',\n",
    "    'Cajun_Creole': 'NorthAmerican',\n",
    "    'Belgium': 'WesternEuropean',\n",
    "    'China': 'EastAsian',\n",
    "    'korean': 'EastAsian',\n",
    "    'Germany': 'WesternEuropean',\n",
    "    'South-America': 'LatinAmerican',\n",
    "    'Spain': 'SouthernEuropean',\n",
    "    'Netherlands': 'WesternEuropean',\n",
    "    'Scandinavia': 'NorthernEuropean',\n",
    "    'Philippines': 'SoutheastAsian',\n",
    "    'Indonesia': 'SoutheastAsian',\n",
    "    'East-African': 'African',\n",
    "    'Scandinavian': 'NorthernEuropean',\n",
    "    'Greek': 'SouthernEuropean',\n",
    "    'American': 'NorthAmerican',\n",
    "    'Vietnam': 'SoutheastAsian',\n",
    "    'western': 'WesternEuropean',\n",
    "    'African': 'African',\n",
    "    'Switzerland': 'WesternEuropean',\n",
    "    'West-African': 'African',\n",
    "    'France': 'WesternEuropean',\n",
    "    'Thai': 'SoutheastAsian',\n",
    "    'Thailand': 'SoutheastAsian',\n",
    "    'Italian': 'SouthernEuropean',\n",
    "    'Pakistan': 'SouthAsian',\n",
    "    'Irish': 'WesternEuropean',\n",
    "    'Mexican': 'LatinAmerican',\n",
    "    'Portugal': 'SouthernEuropean',\n",
    "    'Chinese': 'EastAsian',\n",
    "    'Mexico': 'LatinAmerican',\n",
    "    'German': 'WesternEuropean',\n",
    "    'Spanish_Portuguese': 'SouthernEuropean',\n",
    "    'India': 'SouthAsian',\n",
    "    'Japanese': 'EastAsian',\n",
    "    'Moroccan': 'African',\n",
    "    'Southern_SoulFood': 'NorthAmerican',\n",
    "    'Malaysia': 'SoutheastAsian',\n",
    "    'Austria': 'WesternEuropean',\n",
    "    'English_Scottish': 'WesternEuropean',\n",
    "    'Asian': 'EastAsian',\n",
    "    'Southwestern': 'NorthAmerican',\n",
    "    'Japan': 'EastAsian',\n",
    "    'italian': 'SouthernEuropean',\n",
    "    'canadian': 'NorthAmerican',\n",
    "    'eastern_european_russian': 'EasternEuropean',\n",
    "    'southern_soul_food': 'NorthAmerican',\n",
    "    'middle_eastern': 'MiddleEastern',\n",
    "    'central_south_american': 'LatinAmerican',\n",
    "    'spanish': 'SouthernEuropean',\n",
    "    'north_african': 'African',\n",
    "    'portuguese': 'SouthernEuropean',\n",
    "    'filipino': 'SoutheastAsian',\n",
    "    'dutch': 'WesternEuropean',\n",
    "    'iranian': 'MiddleEastern',\n",
    "    'austrian': 'WesternEuropean',\n",
    "    'swiss': 'WesternEuropean',\n",
    "    'pakistani': 'SouthAsian',\n",
    "    'malaysian': 'SoutheastAsian',\n",
    "    'south_african': 'African',\n",
    "    'west_african': 'African',\n",
    "    'indonesian': 'SoutheastAsian',\n",
    "    'belgian': 'WesternEuropean',\n",
    "    'east_african': 'African',\n",
    "    'israeli': 'MiddleEastern',\n",
    "    'bangladeshi': 'SouthAsian'\n",
    "}\n",
    "\n",
    "mapping = pd.DataFrame(list(data.items()), columns=['country', 'region'])\n",
    "\n",
    "# Clean the data\n",
    "mapping['country'] = mapping['country'].str.strip()\n",
    "mapping['region'] = mapping['region'].str.strip()\n",
    "\n",
    "# Get unique regions and countries\n",
    "unique_regions = mapping['region'].unique()\n",
    "unique_countries = mapping['country'].unique()\n",
    "\n",
    "regions_countries = mapping.groupby('region')['country'].apply(list).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7e697ab11e01de3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:51:37.988194Z",
     "start_time": "2024-06-18T19:51:35.174329Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the cuisine mapping with adjectival forms and variations\n",
    "cuisine_mapping = {\n",
    "    'vietnamese': ['vietnamese', 'vietnam'],\n",
    "    'indian': ['indian', 'india'],\n",
    "    'spanish_portuguese': ['spanish_portuguese'],\n",
    "    'jewish': ['jewish'],\n",
    "    'french': ['french', 'france'],\n",
    "    'central_south_american': ['central_southamerican'],\n",
    "    'cajun_creole': ['cajun_creole'],\n",
    "    'thai': ['thai', 'thailand'],\n",
    "    'scandinavian': ['scandinavian', 'scandinavia'],\n",
    "    'greek': ['greek'],\n",
    "    'american': ['american'],\n",
    "    'african': ['african'],\n",
    "    'middle_eastern': ['middleeastern', 'middle_eastern', 'turkey', 'iran', 'israel', 'lebanon'],\n",
    "    'eastern_european_russian': ['easterneuropean_russian', 'eastern-europe', 'russia'],\n",
    "    'italian': ['italian', 'italy'],\n",
    "    'irish': ['irish', 'ireland'],\n",
    "    'mexican': ['mexican', 'mexico'],\n",
    "    'chinese': ['chinese', 'china'],\n",
    "    'german': ['german', 'germany'],\n",
    "    'mediterranean': ['mediterranean'],\n",
    "    'japanese': ['japanese', 'japan'],\n",
    "    'moroccan': ['moroccan'],\n",
    "    'southern_soul_food': ['southern_soulfood'],\n",
    "    'english_scottish': ['english_scottish', 'uk-and-ireland', 'england', 'scotland'],\n",
    "    'asian': ['asian'],\n",
    "    'southwestern': ['southwestern'],\n",
    "    'east_asian': ['east_asian'],\n",
    "    'western': ['western'],\n",
    "    'korean': ['korean', 'korea'],\n",
    "    'canadian': ['canada'],\n",
    "    'caribbean': ['caribbean'],\n",
    "    'bangladeshi': ['bangladesh'],\n",
    "    'israeli': ['israel'],\n",
    "    'iranian': ['iran'],\n",
    "    'south_african': ['south-african'],\n",
    "    'belgian': ['belgium'],\n",
    "    'spanish': ['spain'],\n",
    "    'dutch': ['netherlands'],\n",
    "    'filipino': ['philippines'],\n",
    "    'indonesian': ['indonesia'],\n",
    "    'east_african': ['east-african'],\n",
    "    'swiss': ['switzerland'],\n",
    "    'west_african': ['west-african'],\n",
    "    'north_african': ['north-african'],\n",
    "    'pakistani': ['pakistan'],\n",
    "    'portuguese': ['portugal'],\n",
    "    'malaysian': ['malaysia'],\n",
    "    'austrian': ['austria']\n",
    "}\n",
    "\n",
    "# Reverse the mapping for easier lookup\n",
    "cuisine_lookup = {alias: cuisine for cuisine, aliases in cuisine_mapping.items() for alias in aliases}\n",
    "\n",
    "\n",
    "\n",
    "# Create a dictionary from the mapping DataFrame\n",
    "country_to_region = dict(zip(mapping['country'].str.lower().str.replace(' ', '_'), mapping['region'].str.lower().str.replace(' ', '_')))\n",
    "\n",
    "# Explicitly format region names\n",
    "def format_region_name(region):\n",
    "    if pd.isna(region):\n",
    "        return 'unknown'\n",
    "    formatted_region = region.replace('southeastasian', 'south_east_asian') \\\n",
    "        .replace('southasian', 'south_asian') \\\n",
    "        .replace('southerneuropean', 'southern_european') \\\n",
    "        .replace('middleeastern', 'middle_eastern') \\\n",
    "        .replace('westerneuropean', 'western_european') \\\n",
    "        .replace('latinamerican', 'latin_american') \\\n",
    "        .replace('northamerican', 'north_american') \\\n",
    "        .replace('northerneuropean', 'northern_european') \\\n",
    "        .replace('easterneuropean', 'eastern_european') \\\n",
    "        .replace('eastasian', 'east_asian')\n",
    "    return formatted_region\n",
    "\n",
    "# Function to standardize country names and map to region\n",
    "def standardize_and_map_region(country):\n",
    "    if pd.isna(country):\n",
    "        return 'unknown', 'unknown'\n",
    "    country_lower = str(country).lower().replace(' ', '_')\n",
    "    standardized_country = cuisine_lookup.get(country_lower, country_lower)\n",
    "    region = country_to_region.get(standardized_country, 'unknown')\n",
    "    return standardized_country, format_region_name(region)\n",
    "\n",
    "\n",
    "# Apply the function to create new columns\n",
    "ingredients_df[['country', 'region']] = ingredients_df['country'].apply(lambda x: pd.Series(standardize_and_map_region(x)))\n",
    "\n",
    "# Move the 'region' column to the beginning\n",
    "columns = ['region'] + [col for col in ingredients_df if col != 'region']\n",
    "ingredients_df = ingredients_df[columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df1f2384e1da1eb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:51:42.467568Z",
     "start_time": "2024-06-18T19:51:38.631877Z"
    }
   },
   "outputs": [],
   "source": [
    "ingredients_df.replace({'Yes': 1, 'No': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "814e3695cf56c37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:51:44.676011Z",
     "start_time": "2024-06-18T19:51:44.673559Z"
    }
   },
   "outputs": [],
   "source": [
    "ingr_small = ingredients_df.columns.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fcf2932fb558d203",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:51:45.358361Z",
     "start_time": "2024-06-18T19:51:45.356222Z"
    }
   },
   "outputs": [],
   "source": [
    "ingr_small = pd.DataFrame(data=ingr_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a618eb36e14b59b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:51:46.461474Z",
     "start_time": "2024-06-18T19:51:46.455549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ingredient_id ingredient_name\n",
      "2                1          almond\n",
      "3                2        angelica\n",
      "4                3           anise\n",
      "5                4      anise_seed\n",
      "6                5           apple\n",
      "..             ...             ...\n",
      "380            379            wood\n",
      "381            380             yam\n",
      "382            381           yeast\n",
      "383            382          yogurt\n",
      "384            383        zucchini\n",
      "\n",
      "[383 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assign column names if necessary\n",
    "ingr_small.columns = ['ingredient_name']\n",
    "\n",
    "# Drop rows that contain 'region' or 'country'\n",
    "ingr_small = ingr_small[~ingr_small['ingredient_name'].isin(['region', 'country'])]\n",
    "\n",
    "# Add ingredient_id column\n",
    "ingr_small.insert(0, 'ingredient_id', range(1, 1 + len(ingr_small)))\n",
    "\n",
    "# Print the cleaned DataFrame\n",
    "print(ingr_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "59fb463813a402d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:51:49.976494Z",
     "start_time": "2024-06-18T19:51:49.952601Z"
    }
   },
   "outputs": [],
   "source": [
    "ingr_small['ingredient_name'] = ingr_small['ingredient_name'].apply(replace_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "337735c4038def35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:51:50.958747Z",
     "start_time": "2024-06-18T19:51:50.945796Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to replace ingredient IDs\n",
    "def replace_ingredient_id(ingr_small, ingr_df):\n",
    "    # Create a dictionary for quick lookup of ingredient_id by ingredient_name\n",
    "    ingr_dict = pd.Series(ingr_df.ingredient_id.values, index=ingr_df.ingredient_name).to_dict()\n",
    "\n",
    "    # Function to replace ingredient_id if ingredient_name matches\n",
    "    def replace_id(row):\n",
    "        ingredient_name = row['ingredient_name']\n",
    "        if ingredient_name in ingr_dict:\n",
    "            row['ingredient_id'] = ingr_dict[ingredient_name]\n",
    "        return row\n",
    "\n",
    "    # Apply the function to each row in ingr_small\n",
    "    ingr_small = ingr_small.apply(replace_id, axis=1)\n",
    "\n",
    "    return ingr_small\n",
    "\n",
    "# Apply the function\n",
    "ingr_small = replace_ingredient_id(ingr_small, ingr_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e55fb367992d9d65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:51:53.199365Z",
     "start_time": "2024-06-18T19:51:53.197054Z"
    }
   },
   "outputs": [],
   "source": [
    "ingr_small_def = ingr_small.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "548dfb4066472c08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:52:11.503166Z",
     "start_time": "2024-06-18T19:52:11.499953Z"
    }
   },
   "outputs": [],
   "source": [
    "ingr_comp_merge = ingr_comp_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3a528850b754f6ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:52:12.313031Z",
     "start_time": "2024-06-18T19:52:12.303806Z"
    }
   },
   "outputs": [],
   "source": [
    "ingr_comp_merge.compound_id = ingr_comp_merge.compound_id.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bca6a8b5db20e430",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:52:18.419721Z",
     "start_time": "2024-06-18T19:52:14.466053Z"
    }
   },
   "outputs": [],
   "source": [
    "ingr_small['ingredient_id'] = ingr_small['ingredient_id'].astype(str)\n",
    "ingr_comp_df['ingredient_id'] = ingr_comp_df['ingredient_id'].astype(str)\n",
    "ingr_comp_df['compound_id'] = ingr_comp_df['compound_id'].astype(str)\n",
    "\n",
    "# Convert column names in ingr_small to strings\n",
    "ingr_small.columns = ingr_small.columns.astype(str)\n",
    "\n",
    "# Get the unique compound_ids in ingr_comp_df\n",
    "compound_id_list = ingr_comp_df['compound_id'].unique()\n",
    "\n",
    "# Create a DataFrame to hold the new columns with initial values set to 0\n",
    "new_columns_df = pd.DataFrame(0, index=ingr_small.index, columns=compound_id_list)\n",
    "\n",
    "# Concatenate the new columns to ingr_small\n",
    "ingr_small = pd.concat([ingr_small, new_columns_df], axis=1)\n",
    "\n",
    "# Iterate through ingr_comp_df and update the values in ingr_small\n",
    "for index, row in ingr_comp_df.iterrows():\n",
    "    ingredient_id = row['ingredient_id']\n",
    "    compound_id = row['compound_id']\n",
    "    if ingredient_id in ingr_small['ingredient_id'].values:\n",
    "        ingr_small.loc[ingr_small['ingredient_id'] == ingredient_id, compound_id] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "72606dce63aba073",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:53:23.391049Z",
     "start_time": "2024-06-18T19:53:23.387165Z"
    }
   },
   "outputs": [],
   "source": [
    "compound_id_cols = [col for col in ingr_small.columns if col not in ['ingredient_id', 'ingredient_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a6dd7ed710ad88ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:53:23.991082Z",
     "start_time": "2024-06-18T19:53:23.985918Z"
    }
   },
   "outputs": [],
   "source": [
    "ingr_small['count_ones'] = ingr_small[compound_id_cols].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8ea77573e05c6ebb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:53:42.081837Z",
     "start_time": "2024-06-18T19:53:42.043233Z"
    }
   },
   "outputs": [],
   "source": [
    "# Group by 'ingredient_id' and aggregate 'compound_id' into a list\n",
    "comp_per_ingr = ingr_comp_df.groupby('ingredient_id')['compound_id'].apply(list).reset_index()\n",
    "ingr_per_comp = ingr_comp_df.groupby('compound_id')['ingredient_id'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "50dd055af9971cdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:53:42.597792Z",
     "start_time": "2024-06-18T19:53:42.594790Z"
    }
   },
   "outputs": [],
   "source": [
    "ingr_per_comp.sort_values(by='compound_id', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c93886d13c59d88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:53:48.931938Z",
     "start_time": "2024-06-18T19:53:48.929385Z"
    }
   },
   "outputs": [],
   "source": [
    "ingr_small['ingredient_name'] = ingr_small['ingredient_name'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eed821a99128f88a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:53:51.752286Z",
     "start_time": "2024-06-18T19:53:51.750426Z"
    }
   },
   "outputs": [],
   "source": [
    "ingredient_cols = ingredients_df.columns.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4db528d19a0ac2d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:54:12.577712Z",
     "start_time": "2024-06-18T19:54:12.575330Z"
    }
   },
   "outputs": [],
   "source": [
    "ingr_small_mapping = ingr_small['ingredient_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "552385d7c74fe587",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:54:17.550060Z",
     "start_time": "2024-06-18T19:54:17.546779Z"
    }
   },
   "outputs": [],
   "source": [
    "ingr_small_mapping = pd.concat([ingr_small_mapping, ingr_small['ingredient_id']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cb690abf340abc41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:54:18.129278Z",
     "start_time": "2024-06-18T19:54:18.126126Z"
    }
   },
   "outputs": [],
   "source": [
    "ingredients_df.columns = ingredients_df.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3033f355baf7c83e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:54:22.639001Z",
     "start_time": "2024-06-18T19:54:22.635898Z"
    }
   },
   "outputs": [],
   "source": [
    "ingredient_name_to_id = dict(zip(ingr_small_mapping['ingredient_name'], ingr_small_mapping['ingredient_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4f1bf65eebddc84a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:54:27.531646Z",
     "start_time": "2024-06-18T19:54:27.528080Z"
    }
   },
   "outputs": [],
   "source": [
    "new_columns = []\n",
    "\n",
    "# Iterate over the current columns and replace ingredient names with IDs, formatted as ingr_{ingredient_id}\n",
    "for col in ingredients_df.columns:\n",
    "    if col in ['region', 'country']:  # Keep these columns as is\n",
    "        new_columns.append(col)\n",
    "    else:\n",
    "        # Replace ingredient names with their corresponding IDs and format as ingr_{ingredient_id}\n",
    "        ingredient_id = ingredient_name_to_id.get(col, col)\n",
    "        new_columns.append(f'ingr_{ingredient_id}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ea780a09cc29162e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:54:27.622067Z",
     "start_time": "2024-06-18T19:54:27.619787Z"
    }
   },
   "outputs": [],
   "source": [
    "ingredients_df.columns = new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3c6660110012dc70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T19:54:35.721370Z",
     "start_time": "2024-06-18T19:54:35.718698Z"
    }
   },
   "outputs": [],
   "source": [
    "ingredients_df.columns = ingredients_df.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c3b056b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries associated with the 'unknown' region:\n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "unknown_countries = ingredients_df.loc[ingredients_df['region'] == 'unknown', 'country'].value_counts()\n",
    "\n",
    "# Print the results\n",
    "print(\"Countries associated with the 'unknown' region:\")\n",
    "print(unknown_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2b375022",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredient_id_to_name = {v: k for k, v in ingredient_name_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "526ebf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients_df_with_names = ingredients_df.copy()\n",
    "\n",
    "# Create new column names by replacing ingredient IDs with names using the reverse mapping\n",
    "new_columns_with_names = []\n",
    "\n",
    "for col in ingredients_df.columns:\n",
    "    if col in ['region', 'country']:  # Keep these columns as is\n",
    "        new_columns_with_names.append(col)\n",
    "    else:\n",
    "        # Extract the ID from the column name (e.g., 'ingr_18' -> '18')\n",
    "        ingredient_id = col.replace('ingr_', '')\n",
    "        # Get the ingredient name from the ID\n",
    "        ingredient_name = ingredient_id_to_name.get(ingredient_id, ingredient_id)\n",
    "        new_columns_with_names.append(ingredient_name)\n",
    "\n",
    "\n",
    "ingredients_df_with_names.columns = new_columns_with_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "92e1f369",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingr_small_copy = ingr_small.copy()\n",
    "\n",
    "# Extract the columns representing the compounds (excluding the first two columns)\n",
    "compound_columns = ingr_small_copy.columns[2:]\n",
    "\n",
    "# Create a new column to contain lists of the names of the columns with a value of 1\n",
    "ingr_small_copy['compounds_present'] = ingr_small_copy.apply(lambda row: list(compound_columns[row[compound_columns] == 1]), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "76914cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['ingredient_name', 'compounds_present']\n",
    "ingr_small_copy = ingr_small_copy[columns_to_keep]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "57a0475f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>south_east_asian</th>\n",
       "      <th>south_asian</th>\n",
       "      <th>southern_european</th>\n",
       "      <th>middle_eastern</th>\n",
       "      <th>western_european</th>\n",
       "      <th>latin_american</th>\n",
       "      <th>north_american</th>\n",
       "      <th>northern_european</th>\n",
       "      <th>african</th>\n",
       "      <th>eastern_european</th>\n",
       "      <th>east_asian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">basil</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">carrot</th>\n",
       "      <th>cayenne</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cilantro</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cucumber</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fish</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>garlic</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       south_east_asian  south_asian  southern_european   \n",
       "basil carrot cayenne                9.0          0.0                4.0  \\\n",
       "             cilantro               9.0          1.0                0.0   \n",
       "             cucumber               6.0          0.0                0.0   \n",
       "             fish                   9.0          0.0                1.0   \n",
       "             garlic                10.0          2.0               52.0   \n",
       "\n",
       "                       middle_eastern  western_european  latin_american   \n",
       "basil carrot cayenne              0.0               2.0             5.0  \\\n",
       "             cilantro             0.0               0.0             0.0   \n",
       "             cucumber             0.0               0.0             0.0   \n",
       "             fish                 0.0               1.0             0.0   \n",
       "             garlic               0.0              16.0             7.0   \n",
       "\n",
       "                       north_american  northern_european  african   \n",
       "basil carrot cayenne             32.0                0.0      0.0  \\\n",
       "             cilantro             7.0                0.0      0.0   \n",
       "             cucumber            11.0                0.0      0.0   \n",
       "             fish                 2.0                0.0      0.0   \n",
       "             garlic             173.0                0.0      1.0   \n",
       "\n",
       "                       eastern_european  east_asian  \n",
       "basil carrot cayenne                1.0        10.0  \n",
       "             cilantro               0.0        10.0  \n",
       "             cucumber               0.0         5.0  \n",
       "             fish                   0.0         9.0  \n",
       "             garlic                 1.0        11.0  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "\n",
    "def safe_literal_eval(val):\n",
    "    try:\n",
    "        return ast.literal_eval(val)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return val\n",
    "\n",
    "# Convert compounds_present column from string to list of integers\n",
    "ingr_small_copy['compounds_present'] = ingr_small_copy['compounds_present'].apply(safe_literal_eval)\n",
    "\n",
    "# Step 1: Calculate prevalence of each ingredient in each cuisine\n",
    "ingredient_prevalence = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# Iterate over rows of ingredients_df_with_names\n",
    "for index, row in ingredients_df_with_names.iterrows():\n",
    "    region = row['region']\n",
    "    ingredients = row.drop(['region', 'country'])\n",
    "    present_ingredients = ingredients.index[ingredients == 1]\n",
    "    for ingredient in present_ingredients:\n",
    "        ingredient_prevalence[region][ingredient] += 1\n",
    "\n",
    "# Convert ingredient prevalence to DataFrame\n",
    "ingredient_prevalence_df = pd.DataFrame(ingredient_prevalence).fillna(0)\n",
    "\n",
    "# Step 2: Calculate relative prevalence (authenticity)\n",
    "Nc = ingredient_prevalence_df.sum(axis=0)  # Total number of recipes per cuisine\n",
    "Pc0 = ingredient_prevalence_df.sum(axis=1) / len(ingredient_prevalence_df.columns)  # Prevalence of each ingredient across all cuisines\n",
    "\n",
    "relative_prevalence = pd.DataFrame(index=ingredient_prevalence_df.index, columns=ingredient_prevalence_df.columns)\n",
    "for cuisine in relative_prevalence.columns:\n",
    "    relative_prevalence[cuisine] = (ingredient_prevalence_df[cuisine] / Nc[cuisine]) - Pc0\n",
    "\n",
    "# Step 3: Identify ingredient pairs and triplets that are overrepresented in each cuisine\n",
    "pair_prevalence = defaultdict(lambda: defaultdict(int))\n",
    "triplet_prevalence = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# Iterate over rows of ingredients_df again to find pairs and triplets\n",
    "for index, row in ingredients_df_with_names.iterrows():\n",
    "    region = row['region']\n",
    "    ingredients = row.drop(['region', 'country'])\n",
    "    present_ingredients = ingredients.index[ingredients == 1]\n",
    "    for i in range(len(present_ingredients)):\n",
    "        for j in range(i + 1, len(present_ingredients)):\n",
    "            pair_prevalence[region][(present_ingredients[i], present_ingredients[j])] += 1\n",
    "    for i in range(len(present_ingredients)):\n",
    "        for j in range(i + 1, len(present_ingredients)):\n",
    "            for k in range(j + 1, len(present_ingredients)):\n",
    "                triplet_prevalence[region][(present_ingredients[i], present_ingredients[j], present_ingredients[k])] += 1\n",
    "\n",
    "# Convert pair and triplet prevalence to DataFrames\n",
    "pair_prevalence_df = pd.DataFrame(pair_prevalence).fillna(0)\n",
    "triplet_prevalence_df = pd.DataFrame(triplet_prevalence).fillna(0)\n",
    "\n",
    "# Display or further analyze the results\n",
    "relative_prevalence.head()\n",
    "pair_prevalence_df.head()\n",
    "triplet_prevalence_df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "01407346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 pairs for south_east_asian:\n",
      "('fish', 'garlic'): 148.0\n",
      "('cayenne', 'garlic'): 135.0\n",
      "('garlic', 'vegetable_oil'): 132.0\n",
      "('garlic', 'soy_sauce'): 122.0\n",
      "('cayenne', 'fish'): 121.0\n",
      "\n",
      "Top 5 pairs for south_asian:\n",
      "('cumin', 'turmeric'): 271.0\n",
      "('coriander', 'cumin'): 265.0\n",
      "('coriander', 'turmeric'): 246.0\n",
      "('cumin', 'onion'): 225.0\n",
      "('onion', 'turmeric'): 218.0\n",
      "\n",
      "Top 5 pairs for southern_european:\n",
      "('garlic', 'olive_oil'): 1760.0\n",
      "('olive_oil', 'tomato'): 1250.0\n",
      "('garlic', 'tomato'): 1196.0\n",
      "('olive_oil', 'onion'): 1063.0\n",
      "('garlic', 'onion'): 962.0\n",
      "\n",
      "Top 5 pairs for middle_eastern:\n",
      "('egg', 'wheat'): 170.0\n",
      "('garlic', 'olive_oil'): 146.0\n",
      "('olive_oil', 'onion'): 128.0\n",
      "('butter', 'wheat'): 105.0\n",
      "('garlic', 'onion'): 105.0\n",
      "\n",
      "Top 5 pairs for western_european:\n",
      "('butter', 'wheat'): 947.0\n",
      "('egg', 'wheat'): 932.0\n",
      "('butter', 'egg'): 817.0\n",
      "('egg', 'milk'): 509.0\n",
      "('milk', 'wheat'): 503.0\n",
      "\n",
      "Top 5 pairs for latin_american:\n",
      "('cayenne', 'onion'): 1496.0\n",
      "('garlic', 'onion'): 1456.0\n",
      "('cayenne', 'garlic'): 1413.0\n",
      "('onion', 'tomato'): 1338.0\n",
      "('cayenne', 'tomato'): 1278.0\n",
      "\n",
      "Top 5 pairs for north_american:\n",
      "('egg', 'wheat'): 11456.0\n",
      "('butter', 'wheat'): 10940.0\n",
      "('butter', 'egg'): 9304.0\n",
      "('milk', 'wheat'): 7355.0\n",
      "('egg', 'milk'): 6942.0\n",
      "\n",
      "Top 5 pairs for northern_european:\n",
      "('butter', 'wheat'): 120.0\n",
      "('egg', 'wheat'): 100.0\n",
      "('butter', 'egg'): 98.0\n",
      "('milk', 'wheat'): 47.0\n",
      "('butter', 'cream'): 47.0\n",
      "\n",
      "Top 5 pairs for african:\n",
      "('cumin', 'olive_oil'): 121.0\n",
      "('garlic', 'olive_oil'): 107.0\n",
      "('olive_oil', 'onion'): 101.0\n",
      "('cumin', 'onion'): 97.0\n",
      "('garlic', 'onion'): 96.0\n",
      "\n",
      "Top 5 pairs for eastern_european:\n",
      "('egg', 'wheat'): 150.0\n",
      "('butter', 'wheat'): 139.0\n",
      "('butter', 'egg'): 131.0\n",
      "('egg', 'milk'): 78.0\n",
      "('milk', 'wheat'): 74.0\n",
      "\n",
      "Top 5 pairs for east_asian:\n",
      "('garlic', 'soy_sauce'): 1188.0\n",
      "('garlic', 'scallion'): 1122.0\n",
      "('scallion', 'soy_sauce'): 1046.0\n",
      "('cayenne', 'garlic'): 1013.0\n",
      "('garlic', 'ginger'): 948.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the top 5 pairs for each region\n",
    "top_pairs = {}\n",
    "for cuisine in pair_prevalence_df.columns:\n",
    "    sorted_pairs = pair_prevalence_df[cuisine].sort_values(ascending=False).head(5)\n",
    "    top_pairs[cuisine] = sorted_pairs\n",
    "\n",
    "# Display the top pairs for each region\n",
    "for cuisine, pairs in top_pairs.items():\n",
    "    print(f\"Top 5 pairs for {cuisine}:\")\n",
    "    for pair, count in pairs.items():\n",
    "        print(f\"{pair}: {count}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "11d31d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 triplets for south_east_asian:\n",
      "('cayenne', 'fish', 'garlic'): 86.0\n",
      "('coconut', 'coriander', 'cumin'): 76.0\n",
      "('coriander', 'cumin', 'turmeric'): 73.0\n",
      "('coriander', 'cumin', 'pepper'): 72.0\n",
      "('cilantro', 'fish', 'garlic'): 72.0\n",
      "\n",
      "Top 5 triplets for south_asian:\n",
      "('coriander', 'cumin', 'turmeric'): 231.0\n",
      "('cumin', 'onion', 'turmeric'): 184.0\n",
      "('coriander', 'cumin', 'onion'): 174.0\n",
      "('cumin', 'pepper', 'turmeric'): 170.0\n",
      "('coriander', 'fenugreek', 'turmeric'): 169.0\n",
      "\n",
      "Top 5 triplets for southern_european:\n",
      "('garlic', 'olive_oil', 'tomato'): 982.0\n",
      "('garlic', 'olive_oil', 'onion'): 736.0\n",
      "('basil', 'garlic', 'olive_oil'): 688.0\n",
      "('garlic', 'onion', 'tomato'): 669.0\n",
      "('olive_oil', 'onion', 'tomato'): 664.0\n",
      "\n",
      "Top 5 triplets for middle_eastern:\n",
      "('garlic', 'olive_oil', 'onion'): 77.0\n",
      "('butter', 'egg', 'wheat'): 76.0\n",
      "('egg', 'vegetable_oil', 'wheat'): 68.0\n",
      "('garlic', 'lemon_juice', 'olive_oil'): 56.0\n",
      "('cumin', 'garlic', 'olive_oil'): 55.0\n",
      "\n",
      "Top 5 triplets for western_european:\n",
      "('butter', 'egg', 'wheat'): 707.0\n",
      "('egg', 'milk', 'wheat'): 412.0\n",
      "('butter', 'milk', 'wheat'): 385.0\n",
      "('butter', 'egg', 'milk'): 346.0\n",
      "('cream', 'egg', 'wheat'): 266.0\n",
      "\n",
      "Top 5 triplets for latin_american:\n",
      "('cayenne', 'garlic', 'onion'): 1225.0\n",
      "('cayenne', 'onion', 'tomato'): 1117.0\n",
      "('garlic', 'onion', 'tomato'): 1104.0\n",
      "('cayenne', 'garlic', 'tomato'): 1059.0\n",
      "('cumin', 'garlic', 'onion'): 629.0\n",
      "\n",
      "Top 5 triplets for north_american:\n",
      "('butter', 'egg', 'wheat'): 7962.0\n",
      "('egg', 'milk', 'wheat'): 5631.0\n",
      "('egg', 'vanilla', 'wheat'): 5429.0\n",
      "('butter', 'milk', 'wheat'): 5206.0\n",
      "('butter', 'vanilla', 'wheat'): 4773.0\n",
      "\n",
      "Top 5 triplets for northern_european:\n",
      "('butter', 'egg', 'wheat'): 84.0\n",
      "('egg', 'milk', 'wheat'): 38.0\n",
      "('butter', 'milk', 'wheat'): 38.0\n",
      "('butter', 'egg', 'milk'): 34.0\n",
      "('butter', 'cream', 'wheat'): 32.0\n",
      "\n",
      "Top 5 triplets for african:\n",
      "('cumin', 'garlic', 'olive_oil'): 70.0\n",
      "('cumin', 'olive_oil', 'onion'): 67.0\n",
      "('bell_pepper', 'garlic', 'olive_oil'): 58.0\n",
      "('bell_pepper', 'cumin', 'olive_oil'): 56.0\n",
      "('garlic', 'olive_oil', 'onion'): 56.0\n",
      "\n",
      "Top 5 triplets for eastern_european:\n",
      "('butter', 'egg', 'wheat'): 111.0\n",
      "('egg', 'milk', 'wheat'): 66.0\n",
      "('butter', 'egg', 'milk'): 59.0\n",
      "('butter', 'milk', 'wheat'): 58.0\n",
      "('cream', 'egg', 'wheat'): 45.0\n",
      "\n",
      "Top 5 triplets for east_asian:\n",
      "('garlic', 'scallion', 'soy_sauce'): 749.0\n",
      "('cayenne', 'garlic', 'scallion'): 714.0\n",
      "('garlic', 'sesame_oil', 'soy_sauce'): 673.0\n",
      "('garlic', 'ginger', 'soy_sauce'): 641.0\n",
      "('garlic', 'scallion', 'sesame_oil'): 630.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the top 5 triplets for each region\n",
    "top_triplets = {}\n",
    "for cuisine in triplet_prevalence_df.columns:\n",
    "    sorted_triplets = triplet_prevalence_df[cuisine].sort_values(ascending=False).head(5)\n",
    "    top_triplets[cuisine] = sorted_triplets\n",
    "\n",
    "#Display the top triplets for each region\n",
    "for cuisine, triplets in top_triplets.items():\n",
    "    print(f\"Top 5 triplets for {cuisine}:\")\n",
    "    for triplet, count in triplets.items():\n",
    "        print(f\"{triplet}: {count}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b4970d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 compounds in pairs for south_east_asian:\n",
      "704    4325.0\n",
      "798    4273.0\n",
      "554    4221.0\n",
      "524    4107.0\n",
      "292    4027.0\n",
      "Name: south_east_asian, dtype: float64\n",
      "\n",
      "Top 5 compounds in pairs for south_asian:\n",
      "704    5045.0\n",
      "798    4653.0\n",
      "554    4447.0\n",
      "292    4361.0\n",
      "524    4171.0\n",
      "Name: south_asian, dtype: float64\n",
      "\n",
      "Top 5 compounds in pairs for southern_european:\n",
      "554    11176.0\n",
      "798    11099.0\n",
      "292    10777.0\n",
      "136    10106.0\n",
      "734     9990.0\n",
      "Name: southern_european, dtype: float64\n",
      "\n",
      "Top 5 compounds in pairs for middle_eastern:\n",
      "704    4867.0\n",
      "798    4650.0\n",
      "292    4552.0\n",
      "554    4517.0\n",
      "734    4137.0\n",
      "Name: middle_eastern, dtype: float64\n",
      "\n",
      "Top 5 compounds in pairs for western_european:\n",
      "798    11063.0\n",
      "554    10790.0\n",
      "292    10518.0\n",
      "136    10199.0\n",
      "524     9800.0\n",
      "Name: western_european, dtype: float64\n",
      "\n",
      "Top 5 compounds in pairs for latin_american:\n",
      "798    8780.0\n",
      "554    8467.0\n",
      "292    8446.0\n",
      "524    7961.0\n",
      "734    7850.0\n",
      "Name: latin_american, dtype: float64\n",
      "\n",
      "Top 5 compounds in pairs for north_american:\n",
      "798    23999.0\n",
      "292    23417.0\n",
      "554    23210.0\n",
      "136    21375.0\n",
      "524    21372.0\n",
      "Name: north_american, dtype: float64\n",
      "\n",
      "Top 5 compounds in pairs for northern_european:\n",
      "554    2306.0\n",
      "798    2140.0\n",
      "292    2119.0\n",
      "136    2092.0\n",
      "704    2030.0\n",
      "Name: northern_european, dtype: float64\n",
      "\n",
      "Top 5 compounds in pairs for african:\n",
      "704    4024.0\n",
      "554    3538.0\n",
      "798    3510.0\n",
      "292    3385.0\n",
      "734    3176.0\n",
      "Name: african, dtype: float64\n",
      "\n",
      "Top 5 compounds in pairs for eastern_european:\n",
      "798    3759.0\n",
      "554    3623.0\n",
      "734    3525.0\n",
      "292    3490.0\n",
      "136    3464.0\n",
      "Name: eastern_european, dtype: float64\n",
      "\n",
      "Top 5 compounds in pairs for east_asian:\n",
      "798    9238.0\n",
      "292    9106.0\n",
      "554    9041.0\n",
      "524    8648.0\n",
      "704    8401.0\n",
      "Name: east_asian, dtype: float64\n",
      "\n",
      "Top 5 compounds in triplets for south_east_asian:\n",
      "704    66501.0\n",
      "798    62932.0\n",
      "554    62631.0\n",
      "524    60117.0\n",
      "292    57477.0\n",
      "Name: south_east_asian, dtype: float64\n",
      "\n",
      "Top 5 compounds in triplets for south_asian:\n",
      "704    71827.0\n",
      "798    60717.0\n",
      "554    54835.0\n",
      "292    54107.0\n",
      "734    53973.0\n",
      "Name: south_asian, dtype: float64\n",
      "\n",
      "Top 5 compounds in triplets for southern_european:\n",
      "554    180505.0\n",
      "798    176829.0\n",
      "734    170657.0\n",
      "292    166300.0\n",
      "984    164136.0\n",
      "Name: southern_european, dtype: float64\n",
      "\n",
      "Top 5 compounds in triplets for middle_eastern:\n",
      "704    56296.0\n",
      "798    48122.0\n",
      "554    46722.0\n",
      "734    45696.0\n",
      "292    45091.0\n",
      "Name: middle_eastern, dtype: float64\n",
      "\n",
      "Top 5 compounds in triplets for western_european:\n",
      "554    149370.0\n",
      "798    149082.0\n",
      "734    140791.0\n",
      "292    139195.0\n",
      "704    138817.0\n",
      "Name: western_european, dtype: float64\n",
      "\n",
      "Top 5 compounds in triplets for latin_american:\n",
      "798    127624.0\n",
      "704    123652.0\n",
      "554    122728.0\n",
      "734    121889.0\n",
      "292    118370.0\n",
      "Name: latin_american, dtype: float64\n",
      "\n",
      "Top 5 compounds in triplets for north_american:\n",
      "798    602178.0\n",
      "554    589416.0\n",
      "292    571905.0\n",
      "734    548203.0\n",
      "704    545590.0\n",
      "Name: north_american, dtype: float64\n",
      "\n",
      "Top 5 compounds in triplets for northern_european:\n",
      "554     16219.0\n",
      "292     14284.0\n",
      "704     14251.0\n",
      "1004    14109.0\n",
      "524     14023.0\n",
      "Name: northern_european, dtype: float64\n",
      "\n",
      "Top 5 compounds in triplets for african:\n",
      "704    51295.0\n",
      "798    39765.0\n",
      "554    38730.0\n",
      "177    38720.0\n",
      "734    37990.0\n",
      "Name: african, dtype: float64\n",
      "\n",
      "Top 5 compounds in triplets for eastern_european:\n",
      "554    37492.0\n",
      "798    37235.0\n",
      "734    36879.0\n",
      "704    35381.0\n",
      "772    35085.0\n",
      "Name: eastern_european, dtype: float64\n",
      "\n",
      "Top 5 compounds in triplets for east_asian:\n",
      "798    141671.0\n",
      "554    138726.0\n",
      "292    134782.0\n",
      "524    134703.0\n",
      "704    133858.0\n",
      "Name: east_asian, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize defaultdicts to store compound prevalence in pairs and triplets per region or cuisine\n",
    "pair_compound_prevalence = defaultdict(lambda: defaultdict(int))\n",
    "triplet_compound_prevalence = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# Iterate over pair_prevalence_df to associate compounds_present with pairs\n",
    "for cuisine in pair_prevalence_df.columns:\n",
    "    for pair in pair_prevalence_df.index:\n",
    "        if pair_prevalence_df[cuisine][pair] > 0:\n",
    "            for ingredient in pair:\n",
    "                if ingredient in ingr_small_copy['ingredient_name'].values:\n",
    "                    compounds = ingr_small_copy.loc[ingr_small_copy['ingredient_name'] == ingredient, 'compounds_present'].iloc[0]\n",
    "                    for compound in compounds:\n",
    "                        pair_compound_prevalence[cuisine][compound] += 1\n",
    "\n",
    "# Iterate over triplet_prevalence_df to associate compounds_present with triplets\n",
    "for cuisine in triplet_prevalence_df.columns:\n",
    "    for triplet in triplet_prevalence_df.index:\n",
    "        if triplet_prevalence_df[cuisine][triplet] > 0:\n",
    "            for ingredient in triplet:\n",
    "                if ingredient in ingr_small_copy['ingredient_name'].values:\n",
    "                    compounds = ingr_small_copy.loc[ingr_small_copy['ingredient_name'] == ingredient, 'compounds_present'].iloc[0]\n",
    "                    for compound in compounds:\n",
    "                        triplet_compound_prevalence[cuisine][compound] += 1\n",
    "\n",
    "# Convert defaultdicts to DataFrames\n",
    "pair_compound_prevalence_df = pd.DataFrame(pair_compound_prevalence).fillna(0)\n",
    "triplet_compound_prevalence_df = pd.DataFrame(triplet_compound_prevalence).fillna(0)\n",
    "\n",
    "# Find top compounds_present for each region or cuisine in pairs and triplets\n",
    "top_compounds_per_pair = {}\n",
    "top_compounds_per_triplet = {}\n",
    "\n",
    "for cuisine in pair_compound_prevalence_df.columns:\n",
    "    sorted_compounds_pair = pair_compound_prevalence_df[cuisine].sort_values(ascending=False).head(5)\n",
    "    top_compounds_per_pair[cuisine] = sorted_compounds_pair\n",
    "\n",
    "for cuisine in triplet_compound_prevalence_df.columns:\n",
    "    sorted_compounds_triplet = triplet_compound_prevalence_df[cuisine].sort_values(ascending=False).head(5)\n",
    "    top_compounds_per_triplet[cuisine] = sorted_compounds_triplet\n",
    "\n",
    "# Display or further analyze the results\n",
    "for cuisine, compounds_pair in top_compounds_per_pair.items():\n",
    "    print(f\"Top 5 compounds in pairs for {cuisine}:\")\n",
    "    print(compounds_pair)\n",
    "    print()\n",
    "\n",
    "for cuisine, compounds_triplet in top_compounds_per_triplet.items():\n",
    "    print(f\"Top 5 compounds in triplets for {cuisine}:\")\n",
    "    print(compounds_triplet)\n",
    "    print()\n",
    "#takes minutes.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c15bf1ffe37ba68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fpdf in c:\\users\\cunia\\spiced_academy\\recipe_generator_capstone\\.venv\\lib\\site-packages (1.7.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install fpdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "62f2323b235ec4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "from fpdf import FPDF\n",
    "\n",
    "# Function to safely evaluate a string as a Python literal expression\n",
    "def safe_literal_eval(val):\n",
    "    try:\n",
    "        return ast.literal_eval(val)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return val\n",
    "\n",
    "# Convert compounds_present column from string to list of integers\n",
    "ingr_small_copy['compounds_present'] = ingr_small_copy['compounds_present'].apply(safe_literal_eval)\n",
    "\n",
    "# to create pdf\n",
    "class PDF(FPDF):\n",
    "    def __init__(self, cuisine_name):\n",
    "        super().__init__()\n",
    "        self.cuisine_name = cuisine_name\n",
    "\n",
    "    def header(self):\n",
    "        self.set_font('Arial', 'B', 12)\n",
    "        self.cell(0, 10, f'{self.cuisine_name} Cuisine Report', 0, 1, 'C')\n",
    "\n",
    "    def chapter_title(self, title):\n",
    "        self.set_font('Arial', 'B', 12)\n",
    "        self.cell(0, 10, title, 0, 1, 'L')\n",
    "        self.ln(4)\n",
    "\n",
    "    def chapter_body(self, body):\n",
    "        self.set_font('Arial', '', 12)\n",
    "        self.multi_cell(0, 10, body)\n",
    "        self.ln()\n",
    "\n",
    "# Function to calculate the ingredients with a value of 1 for each region\n",
    "def calculate_ingredients_with_value_1(df):\n",
    "    ingredients_with_1 = {}\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        region = row['region']\n",
    "        counts = {col: 1 for col, value in row.items() if value == 1 and col not in ['region', 'country']}\n",
    "        \n",
    "        # Sort ingredients alphabetically\n",
    "        sorted_ingredients = {k: v for k, v in sorted(counts.items())}\n",
    "\n",
    "        if region not in ingredients_with_1:\n",
    "            ingredients_with_1[region] = sorted_ingredients\n",
    "        else:\n",
    "            ingredients_with_1[region].update(sorted_ingredients)\n",
    "\n",
    "    return ingredients_with_1\n",
    "\n",
    "# Function to calculate the percentage prevalence of an ingredient in a region\n",
    "def percentage_prevalence(ingredient_column, Nc):\n",
    "    Pc_i = ingredient_column.sum() / Nc\n",
    "    return Pc_i\n",
    "\n",
    "# Function to calculate prevalences for each region\n",
    "def calculate_prevalences_by_region(df):\n",
    "    regions = df['region'].unique()\n",
    "    region_prevalences = {}\n",
    "\n",
    "    for region in regions:\n",
    "        region_df = df[df['region'] == region]\n",
    "        \n",
    "        # Calculate Nc for the current region\n",
    "        Nc_region = len(region_df)\n",
    "        \n",
    "        # Calculate the percentage prevalences for each ingredient in the current region\n",
    "        prevalences = {}\n",
    "        for ingredient in region_df.columns[2:]:\n",
    "            prevalences[ingredient] = percentage_prevalence(region_df[ingredient], Nc_region)\n",
    "        \n",
    "        # Sort ingredients by percentage prevalence and take the top 10\n",
    "        sorted_prevalences = sorted(prevalences.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "        sorted_prevalences = {item[0]: item[1] for item in sorted_prevalences}\n",
    "        \n",
    "        # Add the top 10 ingredient prevalences to the current region\n",
    "        region_prevalences[region] = sorted_prevalences\n",
    "    \n",
    "    return region_prevalences\n",
    "\n",
    "# Calculate the ingredients with a value of 1 for each region\n",
    "ingredients_with_1 = calculate_ingredients_with_value_1(ingredients_df_with_names)\n",
    "\n",
    "# Calculate the prevalences for each region\n",
    "region_prevalences = calculate_prevalences_by_region(ingredients_df_with_names)\n",
    "\n",
    "\n",
    "for cuisine, pairs in top_pairs.items():\n",
    "    # Create an instance of PDF for each cuisine with cuisine_name as argument\n",
    "    pdf = PDF(cuisine)\n",
    "\n",
    "    # Add a page\n",
    "    pdf.add_page()\n",
    "\n",
    "    pdf.chapter_title(f\"Top 5 pairs ingredients for {cuisine} cuisine:\")\n",
    "    for pair in pairs.keys():\n",
    "        pdf.chapter_body(f\"{pair}\")\n",
    "    pdf.ln()\n",
    "\n",
    "    pdf.chapter_title(f\"Top 5 triplets ingredients for {cuisine} cuisine:\")\n",
    "    for triplet in top_triplets[cuisine].keys():\n",
    "        pdf.chapter_body(f\"{triplet}\")\n",
    "    pdf.ln()\n",
    "\n",
    "    pdf.chapter_title(f\"Top 5 compounds in pairs for {cuisine} cuisine:\")\n",
    "    for compound in top_compounds_per_pair[cuisine].keys():\n",
    "        pdf.chapter_body(f\"{compound}\")\n",
    "    pdf.ln()\n",
    "\n",
    "    pdf.chapter_title(f\"Top 5 compounds in triplets for {cuisine} cuisine:\")\n",
    "    for compound in top_compounds_per_triplet[cuisine].keys():\n",
    "        pdf.chapter_body(f\"{compound}\")\n",
    "    pdf.ln()\n",
    "\n",
    "    # Add ingredients with value 1\n",
    "    pdf.chapter_title(f\"Ingredients for {cuisine} cuisine:\")\n",
    "    ingredients_list = ', '.join(ingredients_with_1[cuisine].keys())\n",
    "    pdf.chapter_body(ingredients_list)\n",
    "    pdf.ln()\n",
    "\n",
    "    # Add prevalences information\n",
    "    pdf.chapter_title(f\"Top 10 Ingredient Prevalences for {cuisine} cuisine:\")\n",
    "    for ingredient, prevalence in region_prevalences[cuisine].items():\n",
    "        pdf.chapter_body(f\"{ingredient}: {prevalence:.2%}\")\n",
    "    pdf.ln()\n",
    "\n",
    "    # Add additional information from ingr_small_copy\n",
    "    pdf.chapter_title(f\"Compounds for each ingredient for {cuisine}:\")\n",
    "    for ingredient in ingredients_with_1[cuisine].keys():\n",
    "        if ingredient in ingr_small_copy['ingredient_name'].values:\n",
    "            row = ingr_small_copy[ingr_small_copy['ingredient_name'] == ingredient].iloc[0]\n",
    "            compounds_list = ', '.join(map(str, row['compounds_present']))\n",
    "            pdf.chapter_body(f\"Ingredient: {ingredient}\")\n",
    "            pdf.chapter_body(f\"Compounds Present: {compounds_list}\")\n",
    "    pdf.ln()\n",
    "\n",
    "    # Save the PDF with cuisine-specific name\n",
    "    pdf_file_name = f'{cuisine}_analysis.pdf'\n",
    "    pdf.output(pdf_file_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
